{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List\n",
    "from fastcore.basics import typed\n",
    "from fastcore.test import *\n",
    "from toolz import thread_first, thread_last\n",
    "import proseflow.text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def create_embedding_files_for_visualization(metadata, vectors, metadata_headers=None):\n",
    "    \"\"\" Create embedding files for visualization. Sentences can be any kind of metadata \"\"\"\n",
    "    metadata = [*metadata]\n",
    "    assert len(metadata) == len(vectors)\n",
    "\n",
    "    vectors_filepath = f\"/results/vectors.tsv\"\n",
    "    metadata_filepath = f\"results/metadata.tsv\"\n",
    "\n",
    "    out_vectors = open(vectors_filepath, \"w\", encoding=\"utf-8\")\n",
    "    out_metadata = open(metadata_filepath, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    # Meta File Header\n",
    "    if metadata_headers:\n",
    "        out_metadata.write(\"\\t\".join(metadata_headers) + \"\\n\")\n",
    "\n",
    "    for i in range(len(vectors)):\n",
    "        out_metadata.write(\"\\t\".join(metadata[i]) + \"\\n\")\n",
    "        out_vectors.write(\"\\t\".join([str(x) for x in vectors[i]]) + \"\\n\")\n",
    "\n",
    "    out_vectors.close()\n",
    "    out_metadata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pipe(*funcs:List[callable], thread=\"first\"):\n",
    "    thread = thread_first if thread == \"first\" else thread_last\n",
    "    return lambda data: thread(data, *funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_func in txt.STRING_FUNCS: #PYTHON MAGIC\n",
    "    exec(\"%s=getattr(str, s_func)\" %s_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence = pipe(strip,\n",
    "                      lower)\n",
    "\n",
    "test_eq(\"this is a test\", clean_sentence(\"   THIS iS a TEsT  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dedupe_conseq(coll):\n",
    "    \"\"\"\n",
    "    Returns a generator of the elements of coll with consecutive duplicates removed.\n",
    "    \"\"\"\n",
    "    initial = True\n",
    "    prev = None\n",
    "    for e in coll:\n",
    "        if initial or e != prev:\n",
    "            initial = False\n",
    "            yield e\n",
    "        prev = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq([*dedupe_conseq([1,2,3,4,5,5,5,3])], [1, 2, 3, 4, 5, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_seq(has_branch, get_children, root):\n",
    "    \"\"\"\n",
    "    Returns a generator of the nodes in a tree, via a depth-first walk.\n",
    "    ``has_branch`` must be a function of one argument that returns ``True`` if\n",
    "    passed a node that can have children (but may not). ``get_children`` must\n",
    "    be a function of one argument that returns an iterable of the children.\n",
    "    Will only be called on nodes for which ``has_branch`` returns true.\n",
    "    ``root`` is the root node of the tree.\n",
    "    \"\"\"\n",
    "    yield root\n",
    "    if has_branch(root):\n",
    "        for child in get_children(root):\n",
    "            for subchild in tree_seq(has_branch, get_children, child):\n",
    "                yield subchild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 3, 'e': {'f': 6, 'g': 7}}, 'a', 'b', 'e']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"a\": 1, \"b\": 3,\"e\" :{\"f\": 6, \"g\": 7}}\n",
    "[*tree_seq(lambda n: type(n) == dict, lambda x : x, d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted aws_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted load.ipynb.\n",
      "Converted roam_utils.ipynb.\n",
      "Converted semanticscholar_api.ipynb.\n",
      "Converted spec.ipynb.\n",
      "Converted text.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proseflow",
   "language": "python",
   "name": "proseflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
