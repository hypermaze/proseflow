{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from typing import List\n",
    "from fastcore.basics import typed\n",
    "from fastcore.test import *\n",
    "from toolz import thread_first, thread_last\n",
    "import proseflow.text as txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from tabulate import tabulate\n",
    "def show_tabs(doc):\n",
    "    print(tabulate([\n",
    "            [token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop] \n",
    "            for token in doc], headers=[\"token\", \"lemma\", \"POS\", \"Tag\", \"DEP\", \"shape\", \"is_alpha\", \"is_stop\"]\n",
    "  ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [2, 3], [3, 4], [4, 5], [5, 5], [5, 6], [6, 7]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "def take_while(fn, coll):\n",
    "    \"\"\"Yield values from coll until fn is False\"\"\"\n",
    "    for e in coll:\n",
    "        if fn(e):\n",
    "            yield e\n",
    "        else:\n",
    "            return\n",
    "\n",
    "def partition(n, coll, step=None):\n",
    "    return take_while(lambda e: len(e) == n,\n",
    "        (coll[i:i+n] for i in range(0, len(coll), step or n)))\n",
    "\n",
    "def partition_all(n, coll, step=None):\n",
    "    return (coll[i:i+n] for i in range(0, len(coll), step or n))\n",
    "\n",
    "[*partition(2, [1, 2,3 ,4,5, 5,6,7], 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typed\n",
    "def create_embedding_files_for_visualization(metadata, vectors, metadata_headers=None):\n",
    "    \"\"\" Create embedding files for visualization. Sentences can be any kind of metadata \"\"\"\n",
    "    metadata = [*metadata]\n",
    "    assert len(metadata) == len(vectors)\n",
    "\n",
    "    vectors_filepath = f\"/results/vectors.tsv\"\n",
    "    metadata_filepath = f\"results/metadata.tsv\"\n",
    "\n",
    "    out_vectors = open(vectors_filepath, \"w\", encoding=\"utf-8\")\n",
    "    out_metadata = open(metadata_filepath, \"w\", encoding=\"utf-8\")\n",
    "\n",
    "    # Meta File Header\n",
    "    if metadata_headers:\n",
    "        out_metadata.write(\"\\t\".join(metadata_headers) + \"\\n\")\n",
    "\n",
    "    for i in range(len(vectors)):\n",
    "        out_metadata.write(\"\\t\".join(metadata[i]) + \"\\n\")\n",
    "        out_vectors.write(\"\\t\".join([str(x) for x in vectors[i]]) + \"\\n\")\n",
    "\n",
    "    out_vectors.close()\n",
    "    out_metadata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pipe(*funcs:List[callable], thread=\"first\"):\n",
    "    thread = thread_first if thread == \"first\" else thread_last\n",
    "    return lambda data: thread(data, *funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_func in txt.STRING_FUNCS: #PYTHON MAGIC\n",
    "    exec(\"%s=getattr(str, s_func)\" %s_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_sentence = pipe(strip,\n",
    "                      lower)\n",
    "\n",
    "test_eq(\"this is a test\", clean_sentence(\"   THIS iS a TEsT  \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dedupe_conseq(coll):\n",
    "    \"\"\"\n",
    "    Returns a generator of the elements of coll with consecutive duplicates removed.\n",
    "    \"\"\"\n",
    "    initial = True\n",
    "    prev = None\n",
    "    for e in coll:\n",
    "        if initial or e != prev:\n",
    "            initial = False\n",
    "            yield e\n",
    "        prev = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq([*dedupe_conseq([1,2,3,4,5,5,5,3])], [1, 2, 3, 4, 5, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_seq(has_branch, get_children, root):\n",
    "    \"\"\"\n",
    "    Returns a generator of the nodes in a tree, via a depth-first walk.\n",
    "    ``has_branch`` must be a function of one argument that returns ``True`` if\n",
    "    passed a node that can have children (but may not). ``get_children`` must\n",
    "    be a function of one argument that returns an iterable of the children.\n",
    "    Will only be called on nodes for which ``has_branch`` returns true.\n",
    "    ``root`` is the root node of the tree.\n",
    "    \"\"\"\n",
    "    yield root\n",
    "    if has_branch(root):\n",
    "        for child in get_children(root):\n",
    "            for subchild in tree_seq(has_branch, get_children, child):\n",
    "                yield subchild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1, 'b': 3, 'e': {'f': 6, 'g': 7}}, 'a', 'b', 'e']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"a\": 1, \"b\": 3,\"e\" :{\"f\": 6, \"g\": 7}}\n",
    "[*tree_seq(lambda n: type(n) == dict, lambda x : x, d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted aws_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted load.ipynb.\n",
      "Converted roam_utils.ipynb.\n",
      "Converted semanticscholar_api.ipynb.\n",
      "Converted spec.ipynb.\n",
      "Converted text.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proseflow",
   "language": "python",
   "name": "proseflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
