{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "from proseflow.load import load\n",
    "from proseflow.pubmed import _get_pubmed_records, _get_pubmed_abstracts\n",
    "from proseflow.save import save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def chunker(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/csv-cancerimmu-set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import copy\n",
    "# from proseflow.utils import merge_csv_in_dir\n",
    "\n",
    "# for idx, dfc in enumerate(chunker(df, 100)):\n",
    "#     d = copy.deepcopy(dfc)\n",
    "\n",
    "#     d[\"Abstract\"] = _get_pubmed_abstracts(list(d[\"PMID\"].map(str)))\n",
    "#     save(d, \"../data/pm_cancer/\" + str(idx))\n",
    "    \n",
    "    \n",
    "# merge_csv_in_dir(\"../data/pm_cancer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-bikini",
   "metadata": {},
   "source": [
    "## Parse in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-weather",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 17:36:20 INFO: Loading these models for language: en (English):\n",
      "==========================\n",
      "| Processor | Package    |\n",
      "--------------------------\n",
      "| tokenize  | genia      |\n",
      "| pos       | genia      |\n",
      "| lemma     | genia      |\n",
      "| depparse  | genia      |\n",
      "| ner       | bionlp13cg |\n",
      "==========================\n",
      "\n",
      "2021-02-25 17:36:20 INFO: Use device: cpu\n",
      "2021-02-25 17:36:20 INFO: Loading: tokenize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'re': 'stanza', 'doc': \"Stanford's Stanza Model\", 'options': ['stanza1', 'stanza2']} shape {}\n",
      "loading stanza {'lang': 'en', 'package': 'genia', 'processors': {'ner': 'bionlp13cg'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-25 17:36:20 INFO: Loading: pos\n",
      "2021-02-25 17:36:21 INFO: Loading: lemma\n",
      "2021-02-25 17:36:21 INFO: Loading: depparse\n",
      "2021-02-25 17:36:23 INFO: Loading: ner\n",
      "2021-02-25 17:36:24 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "from spacy_stanza import StanzaLanguage\n",
    "\n",
    "snlp = load(\"stanza\")\n",
    "nlp = StanzaLanguage(snlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/cancer_immun.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.corpus import Corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-spectrum",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Abstract\"][740:1000])\n",
    "docs = []\n",
    "corpus = Corpus(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for idx, c in enumerate(chunker(df[\"Abstract\"][740:1000], 20)):\n",
    "#     print(idx)\n",
    "#     corpus.add(c)\n",
    "#     corpus.save(\"../data/docs_cancer.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-oliver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proseflow",
   "language": "python",
   "name": "proseflow"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
