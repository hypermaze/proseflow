{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections.abc import Iterable\n",
    "from io import BytesIO\n",
    "from typing import Dict\n",
    "\n",
    "import gspread\n",
    "import pandas as pd\n",
    "import requests\n",
    "import spacy\n",
    "import stanza\n",
    "from dotenv import load_dotenv\n",
    "from multipledispatch import dispatch\n",
    "from pandas import DataFrame\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "from spacy_stanza import StanzaLanguage\n",
    "from textacy.corpus import Corpus\n",
    "from typeguard import typechecked\n",
    "\n",
    "from proseflow.spec import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # TODO: [Markus -> use func.signature()]\n",
    "    # gspreadsheet\n",
    "    # csv\n",
    "    # tsv\n",
    "    # pubmed articles\n",
    "    # wikipedia\n",
    "    # url\n",
    "    # load spacy_corpus\n",
    "    # annotations\n",
    "    # BRAT\n",
    "    # Resource = Union[URL, str, email]\n",
    "# ? @typecheck is pointless here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load\n",
    "\n",
    "> This module loads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function proseflow.spec.gsheet_to_df(worksheet) -> pandas.core.frame.DataFrame>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsheet_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIR_PATH = os.path.dirname(os.path.realpath(__file__))\n",
    "load_dotenv()\n",
    "env_debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: -> converter\n",
    "# Example: https://docs.google.com/spreadsheets/d/1N_aANmDaosjAlodJ5nMNVPfe6REsDtsNYHj_ltH3Q_0/edit?usp=drive_web&ouid=112317186249575590696\n",
    "#export\n",
    "@typechecked\n",
    "def _load_gsheet(\n",
    "    url: str,\n",
    "    sheet_number: int = 0,\n",
    "    credential_path: str = os.getenv(\"GSHEET_CREDENTIALS\"),\n",
    "    **kwargs,\n",
    ") -> GSHEET:\n",
    "    if not credential_path:\n",
    "        raise Exception(\"Add the $GSHEET_CREDENTIALS variable to your .env file.\")\n",
    "    gc = gspread.service_account(filename=credential_path)\n",
    "    wb = gc.open_by_url(url)\n",
    "    worksheet = wb.get_worksheet(sheet_number)\n",
    "\n",
    "    return worksheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _load_corpus(nlp, path):\n",
    "    corpus = Corpus(nlp).load(nlp, path)\n",
    "    for label in labels:\n",
    "        nlp.vocab.strings.add(label)\n",
    "\n",
    "    return corpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: [Rico] make it work with \"stanza\" or \"sci-md\" strings\n",
    "#export\n",
    "@dispatch((spacy.language.Language, StanzaLanguage), str)\n",
    "def load(nlp, path):\n",
    "    return _load_corpus(nlp, path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dispatch(Iterable)\n",
    "def load(resource, **kwargs):\n",
    "    \"\"\"All shapes become lists for further processing\n",
    "    #TODO: [Rico] -- a job for autoconvert?\n",
    "    \"\"\"\n",
    "    shape_iterable = convert(resource, source=type(resource), target=list)\n",
    "    return load(shape_iterable, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO [Rico] cache all sane things\n",
    "#export\n",
    "@dispatch(list)\n",
    "def load(resource, **kwargs):\n",
    "    #! checks the type of the FIRST element (like an actual pmid, not a list of pmids)\n",
    "    shape = kwargs.get(\"input_type\") or infer_type(resource[0])\n",
    "    if shape == PUBMED_IDS:\n",
    "        content = kwargs.get(PUBMED_CONTENT) or \"ALL\"\n",
    "        if content == \"ABSTRACT\":\n",
    "            return _get_pubmed_abstracts(pmids=resource)\n",
    "        if content == \"INFO\":\n",
    "            return _get_pubmed_info(pmids=resource)\n",
    "        return _get_pubmed_records(pmids=resource)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _load_transformer(model_name):\n",
    "    # ! TODO: abstract so that it also works for Tensorflow, etc..; right now its only PyTorch\n",
    "    # TODO: make sure it actually loads a huggingface transformer and not the sentence transformer version\n",
    "    model_name = model_name.split(\":\")[1]\n",
    "\n",
    "    return models.Transformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _load_spacy(model_name: str = \"en_core_web_sm\", **kwargs) -> spacy.language.Language:\n",
    "    print(\"Loading SpaCy...\")\n",
    "    try:\n",
    "        nlp = spacy.load(model_name, **kwargs)\n",
    "    except OSError:\n",
    "        try:\n",
    "            spacy.cli.download(model_name)\n",
    "            nlp = spacy.load(model_name, **kwargs)\n",
    "        except:\n",
    "            print(\"Download the SpaCy model before trying to import it.\")\n",
    "            return None\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _load_stanza(\n",
    "    stanza_setup: Dict[str, str] = {\n",
    "        \"lang\": \"en\",\n",
    "        \"package\": \"genia\",\n",
    "        \"processors\": {\"ner\": \"bionlp13cg\"},\n",
    "    },\n",
    "    use_gpu: bool = True,\n",
    ") -> stanza.Pipeline:\n",
    "    # TODO: [RICO -> put use_gpu inside one config]\n",
    "    print(\"loading stanza\", stanza_setup)\n",
    "    try:\n",
    "        snlp = stanza.Pipeline(**stanza_setup, use_gpu=use_gpu)\n",
    "    except:\n",
    "        stanza.download(**stanza_setup)\n",
    "        snlp = stanza.Pipeline(**stanza_setup, use_gpu=use_gpu)\n",
    "\n",
    "    return snlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@dispatch(str)  # dispatch decides if the load gets executed; the type level is more expressive\n",
    "def load(resource, *args, **kwargs):\n",
    "    \"\"\"This names the important args like config and credentials, but leaves options open\"\"\"\n",
    "\n",
    "\n",
    "    if resource.endswith(\".csv\"):\n",
    "        pass\n",
    "    if resource.endswith(\".tsv\"):\n",
    "        pass\n",
    "    if resource == \"some url\":\n",
    "        pass  # scrape (params:)\n",
    "\n",
    "    shape = kwargs.get(\"input_type\") or infer_type(resource)\n",
    "\n",
    "    as_type = kwargs.get(\"as_type\")\n",
    "    should_convert = as_type is not None\n",
    "    if shape == GSHEET:\n",
    "        gs = _load_gsheet(resource, **kwargs)\n",
    "\n",
    "        # ! Don't Try to be smart here and use (should_convert and convert(...) -- there's problems with boolean\n",
    "        # operators and some types)\n",
    "        if should_convert:\n",
    "            gs = convert(gs, source=GSHEET, target=as_type)\n",
    "            if as_type == DataFrame and kwargs.get(\"columns\"):\n",
    "                gs = gs[kwargs.get(\"columns\")]\n",
    "        return gs\n",
    "    if shape == SPACY_MODEL:\n",
    "        return _load_spacy(resource, **kwargs)\n",
    "    if shape == STANZA_MODEL:\n",
    "        if as_type:\n",
    "            kwargs.pop(\"as_type\")\n",
    "        snlp = _load_stanza(**kwargs)\n",
    "        if as_type:\n",
    "            return convert(snlp, source=STANZA_MODEL, target=SPACY_MODEL)\n",
    "        return snlp\n",
    "    if shape == SENTENCE_TRANSFORMER:\n",
    "        return SentenceTransformer(resource)\n",
    "    if shape == TRANSFORMER:\n",
    "        transformer_model = _load_transformer(resource)\n",
    "        if as_type:\n",
    "            return convert(\n",
    "                transformer_model, source=TRANSFORMER, target=SENTENCE_TRANSFORMER\n",
    "            )\n",
    "        return transformer_model\n",
    "\n",
    "    return \"None found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SpaCy...\n"
     ]
    }
   ],
   "source": [
    "test_eq(type(load(\"en\")), spacy.lang.en.English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SpaCy...\n"
     ]
    }
   ],
   "source": [
    "test_eq(type(load(\"en_core_web_sm\", disable=[\"tagger\", \"ner\", \"parser\"])), spacy.lang.en.English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No Match found in type inference",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-726136addc5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert-base-nli-mean-tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSENTENCE_TRANSFORMER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/proseflow-GKtXBSGs-py3.8/lib/python3.8/site-packages/multipledispatch/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMDNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-a323ec9bb90b>\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource, *args, **kwargs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# scrape (params:)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input_type\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minfer_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mas_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"as_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/proseflow/proseflow/spec.py\u001b[0m in \u001b[0;36minfer_type\u001b[0;34m(form, SPEC)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No Match found in type inference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No Match found in type inference"
     ]
    }
   ],
   "source": [
    "load(\"distilbert-base-nli-mean-tokens\", input_type=SENTENCE_TRANSFORMER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n<class 'str'>\n<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a6ffc6366ece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert-base-nli-mean-tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SENTENCE_TRANSFORMER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/proseflow-GKtXBSGs-py3.8/lib/python3.8/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/proseflow-GKtXBSGs-py3.8/lib/python3.8/site-packages/fastcore/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n<class 'str'>\n<class 'sentence_transformers.SentenceTransformer.SentenceTransformer'>"
     ]
    }
   ],
   "source": [
    "test_eq(type(load(\"distilbert-base-nli-mean-tokens\", input_type=\"SENTENCE_TRANSFORMER\")), SentenceTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "@dispatch(int)\n",
    "def save(what, where):\n",
    "    # spacy_docs_to_corpus -> annotation\n",
    "    # csv\n",
    "    # tsv\n",
    "    # to_local (Binary, String, List[str], List[json], json, dict)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted aws_utils.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted load.ipynb.\n",
      "Converted roam_utils.ipynb.\n",
      "Converted semanticscholar_api.ipynb.\n",
      "Converted spec.ipynb.\n",
      "Converted text.ipynb.\n",
      "Converted utils.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script; notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proseflow",
   "language": "python",
   "name": "proseflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
